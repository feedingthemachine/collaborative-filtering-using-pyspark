{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:26.892416Z",
     "start_time": "2019-10-12T13:51:24.222066Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('local[*]')\\\n",
    "        .appName('prueba')\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la ingesta del archivo con datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.782563Z",
     "start_time": "2019-10-12T13:51:26.904569Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_review = spark.read.json('data/review_train_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos una entrada ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.828327Z",
     "start_time": "2019-10-12T13:51:25.147Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yelp_review.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cuantos registros existen en el conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.831258Z",
     "start_time": "2019-10-12T13:51:25.691Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_review.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos la cantidad de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.833880Z",
     "start_time": "2019-10-12T13:51:26.463Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_review.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo vamos a trabajar sólo con las columnas `user_id`, `business_id` y `stars`. Con el comando `select` las separaremos en un nuevo objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.836819Z",
     "start_time": "2019-10-12T13:51:27.847Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_review = yelp_review.select('user_id', 'business_id', 'stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación del pipeline\n",
    "\n",
    "Para poder entrenar un modelo con ALS, lo que debemos generar es una matriz con datos numéricos. Si revisamos el schema de datos con `yelp_review.printSchema()`, observaremos que tanto `user_id` como `business_id` son strings. Con el método `StringIndexer` podremos pasarlas a numérico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.839576Z",
     "start_time": "2019-10-12T13:51:29.581Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T13:51:29.842218Z",
     "start_time": "2019-10-12T13:51:29.809Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id_indexer = StringIndexer(inputCol=\"user_id\",\n",
    "                               outputCol=\"user_id_indexed\")\n",
    "\n",
    "business_id_indexer = StringIndexer(inputCol='business_id',\n",
    "                                   outputCol='business_id_indexed')\n",
    "\n",
    "pipeline_proc = Pipeline(stages=[user_id_indexer, business_id_indexer])\n",
    "\n",
    "yelp_review_proc = pipeline_proc\\\n",
    "                    .fit(yelp_review)\\\n",
    "                    .transform(yelp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:24.297197Z",
     "start_time": "2019-10-02T18:40:23.630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id='paoW23WEkX17E-lWPn-sSw', business_id='wo41OdU_iUwFofsBnVf6uw', stars=3.0, user_id_indexed=31838.0, business_id_indexed=7277.0),\n",
       " Row(user_id='ilgrAfnldXykcpoBwSMgnQ', business_id='4GJ9B9IUeOYQtqfG_BYwlw', stars=5.0, user_id_indexed=19001.0, business_id_indexed=821.0),\n",
       " Row(user_id='Isf8G6HPbNqEisKDjmUlbw', business_id='L-EF1NxGWjL5LGONbk4hxg', stars=5.0, user_id_indexed=323.0, business_id_indexed=1823.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_review_proc.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación del modelo\n",
    "\n",
    "Para implementar un modelo Alternating Least Squares, es necesario definir la cantidad de factores latentes a identificar, el nombre de las columnas para usuarios e item, así como el rating asociado. También hay que considerar el comportamiento de la estrategia Cold Start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:25.992377Z",
     "start_time": "2019-10-02T18:40:25.960166Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "train_als = ALS(rank=5,\n",
    "                userCol='user_id_indexed',\n",
    "                itemCol='business_id_indexed',\n",
    "                ratingCol='stars',coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo de la manera usual con el método  `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:33.257607Z",
     "start_time": "2019-10-02T18:40:26.875939Z"
    }
   },
   "outputs": [],
   "source": [
    "train_als_model = train_als.fit(yelp_review_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el archivo de helpers tenemos definida una función que nos permite evaluar las cargas de eigenvalues para cada una de las entradas a nivel de usuario e item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:39.728438Z",
     "start_time": "2019-10-02T18:40:39.722404Z"
    }
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:41.211090Z",
     "start_time": "2019-10-02T18:40:40.623298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de usuarios en entrenamiento: 43914\n",
      "Producto punto para los primeros 3 usuarios:\n",
      "Usuario: 0 -> Producto punto: [1.556, -0.517, 0.379, 0.597, -0.195]\n",
      "Usuario: 10 -> Producto punto: [-1.059, -1.306, -1.082, 1.122, 1.601]\n",
      "Usuario: 20 -> Producto punto: [0.809, -0.976, -0.328, 1.099, -0.925]\n",
      "\n",
      "\n",
      "Número de items en entrenamiento: 10607\n",
      "Producto punto para los primeros 10 items:\n",
      "Item: 0 -> Producto punto: [-0.048, 0.138, -0.023, 0.401, -1.507]\n",
      "Item: 10 -> Producto punto: [-0.064, -0.604, -1.125, 0.899, -0.243]\n",
      "Item: 20 -> Producto punto: [-0.725, 0.615, 0.519, -1.514, 0.131]\n",
      "Item: 30 -> Producto punto: [-0.138, 0.274, -1.382, -0.889, -0.423]\n",
      "Item: 40 -> Producto punto: [-0.156, 1.571, -1.246, 0.142, -0.1]\n",
      "Item: 50 -> Producto punto: [1.002, -1.037, -0.061, 0.686, -0.605]\n",
      "Item: 60 -> Producto punto: [-0.216, -0.158, -0.889, 0.003, 0.602]\n",
      "Item: 70 -> Producto punto: [-1.643, 1.141, 0.049, -0.891, -0.079]\n",
      "Item: 80 -> Producto punto: [0.924, -0.891, -0.894, -0.251, 0.033]\n",
      "Item: 90 -> Producto punto: [-0.576, 0.328, -1.712, -0.248, -1.214]\n"
     ]
    }
   ],
   "source": [
    "helpers.get_als_factors_information(train_als_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de predicciones\n",
    "\n",
    "Para generar predicciones, hacemos uso de la función `transform` __en el modelo ya entrenado__. A diferencia de `sklearn`  donde las predicciones retornan un array, en `pyspark` las predicciones son concatenadas como una nueva columna en el `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:43.823151Z",
     "start_time": "2019-10-02T18:40:43.794187Z"
    }
   },
   "outputs": [],
   "source": [
    "get_predictions = train_als_model.transform(yelp_review_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:40:54.055276Z",
     "start_time": "2019-10-02T18:40:44.614737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+---------------+-------------------+----------+\n",
      "|             user_id|         business_id|stars|user_id_indexed|business_id_indexed|prediction|\n",
      "+--------------------+--------------------+-----+---------------+-------------------+----------+\n",
      "|zwCen9VgJspf6yJgD...|yLMSxHjK56Az-KtMQ...|  4.0|        10817.0|              148.0| 3.9144683|\n",
      "|_cIOI0pD1wbEtieG1...|yLMSxHjK56Az-KtMQ...|  3.0|         6376.0|              148.0| 2.9358513|\n",
      "|IkvaB4ij28xrBgh5Q...|yLMSxHjK56Az-KtMQ...|  4.0|        15966.0|              148.0| 3.9144683|\n",
      "|XWZH-5T5pK5nFI4fl...|yLMSxHjK56Az-KtMQ...|  5.0|        19940.0|              148.0| 4.8930855|\n",
      "|dTW_kKKAKyX2fgaYh...|yLMSxHjK56Az-KtMQ...|  5.0|        33761.0|              148.0| 4.8930855|\n",
      "+--------------------+--------------------+-----+---------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "El modelo puede ser evaluado como un problema de regresión o de clasificación. Dado que los ratings  son inherentemente ordinales, existe una jerarquía clara entre las observaciones.\n",
    "\n",
    "Partamos por implementar el evaluador de un problema de regresión basado en los dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:41:34.509768Z",
     "start_time": "2019-10-02T18:41:23.363982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RMSE promedio en el conjunto de entrenamiento es de: 0.1206859139936097\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluate_als = RegressionEvaluator(predictionCol='prediction',labelCol='stars', metricName='rmse')\n",
    "get_rmse = evaluate_als.evaluate(get_predictions)\n",
    "print(f\"El RMSE promedio en el conjunto de entrenamiento es de: {get_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora también podemos implementar un evaluador basado en los RDD de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:41:37.523623Z",
     "start_time": "2019-10-02T18:41:37.120957Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "user_level_prediction = get_predictions\\\n",
    "                        .select('prediction','stars')\\\n",
    "                        .rdd\\\n",
    "                        .map(lambda x: (x[0], x[1]))\n",
    "regression_metrics_output = RegressionMetrics(user_level_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:42:02.989487Z",
     "start_time": "2019-10-02T18:41:40.339601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza Explicada: 2.038\n",
      "Error cuadrático promedio: 0.015\n",
      "Error absoluto promedio: 0.091\n",
      "Raíz del error cuadrático promedio: 0.121\n"
     ]
    }
   ],
   "source": [
    "helpers.report_reg_metrics(regression_metrics_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de recomendaciones\n",
    "\n",
    "Las recomendaciones van a estar disponibles en la función `recommendForAllUsers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:42:07.607628Z",
     "start_time": "2019-10-02T18:42:07.294673Z"
    }
   },
   "outputs": [],
   "source": [
    "get_recommendations_for_users = train_als_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:42:23.710640Z",
     "start_time": "2019-10-02T18:42:08.322720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(recommendations=[Row(business_id_indexed=4562, rating=7.489191055297852), Row(business_id_indexed=6078, rating=7.462268829345703), Row(business_id_indexed=4129, rating=7.460726737976074), Row(business_id_indexed=4351, rating=7.439226150512695), Row(business_id_indexed=2649, rating=7.438721179962158), Row(business_id_indexed=8560, rating=7.433102607727051), Row(business_id_indexed=3185, rating=7.428170204162598), Row(business_id_indexed=6471, rating=7.416937351226807), Row(business_id_indexed=3939, rating=7.413895606994629), Row(business_id_indexed=10278, rating=7.406289577484131)])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_for_users.select('recommendations').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:42:40.570684Z",
     "start_time": "2019-10-02T18:42:27.496421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|user_id_indexed|     recommendations|\n",
      "+---------------+--------------------+\n",
      "|            148|[[4562, 7.489191]...|\n",
      "|            463|[[2488, 6.726735]...|\n",
      "|            471|[[2488, 10.373366...|\n",
      "|            496|[[4675, 4.7120085...|\n",
      "|            833|[[3159, 9.682419]...|\n",
      "|           1088|[[4649, 2.6362147...|\n",
      "|           1238|[[5356, 7.034578]...|\n",
      "|           1342|[[5780, 11.276456...|\n",
      "|           1580|[[4483, 7.444725]...|\n",
      "|           1591|[[4272, 5.2209077...|\n",
      "+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_for_users.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:42:42.591383Z",
     "start_time": "2019-10-02T18:42:42.384952Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "users_predictions = get_predictions\\\n",
    "  .orderBy(col('user_id_indexed'), expr(\"prediction DESC\"))\\\n",
    "  .groupBy('user_id_indexed')\\\n",
    "  .agg(expr('collect_set(business_id_indexed)').alias('user_preds'))\n",
    "\n",
    "get_positive_recs = get_predictions\\\n",
    "  .where('stars > 2.5')\\\n",
    "  .groupBy('user_id_indexed')\\\n",
    "  .agg(expr('collect_set(business_id_indexed)').alias('likely_preds'))\n",
    "  \n",
    "user_divergence = get_positive_recs.join(users_predictions,['user_id_indexed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:43:06.747720Z",
     "start_time": "2019-10-02T18:42:53.866544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([3616.0, 729.0, 4713.0, 1252.0], [3616.0, 729.0, 4713.0, 1252.0]),\n",
       " ([3630.0, 10464.0, 608.0, 2931.0], [3630.0, 10464.0, 608.0, 2931.0])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_divergence.rdd.map(lambda x: (x[1], x[2])).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_metrics = RankingMetrics(user_divergence.rdd.map(lambda x: (x[1], x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844389850334991"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_metrics.meanAveragePrecision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación en Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:43:08.539785Z",
     "start_time": "2019-10-02T18:43:07.784357Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_test = spark.read\\\n",
    "                .json('data/review_test_data.json')\\\n",
    "                .select('user_id', 'business_id', 'stars')\n",
    "yelp_test_proc = pipeline_proc\\\n",
    "                    .fit(yelp_test)\\\n",
    "                    .transform(yelp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:43:10.134343Z",
     "start_time": "2019-10-02T18:43:10.116866Z"
    }
   },
   "outputs": [],
   "source": [
    "get_predictions_on_test = train_als_model.transform(yelp_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:43:22.256988Z",
     "start_time": "2019-10-02T18:43:11.668272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+---------------+-------------------+-----------+\n",
      "|             user_id|         business_id|stars|user_id_indexed|business_id_indexed| prediction|\n",
      "+--------------------+--------------------+-----+---------------+-------------------+-----------+\n",
      "|5ELA1Xm-xeE8oj_In...|gA9hCYY7MYl9oZ3ay...|  5.0|         1829.0|              148.0|-0.06538749|\n",
      "|mWHhRg6twaUGlqjYg...|gA9hCYY7MYl9oZ3ay...|  5.0|        14752.0|              148.0|  3.4248352|\n",
      "|GXK2LOBctKVg7jpld...|gA9hCYY7MYl9oZ3ay...|  5.0|        28057.0|              148.0|  2.3234031|\n",
      "|VFJwV-4OxcxtTM7ME...|gA9hCYY7MYl9oZ3ay...|  1.0|        11081.0|              148.0| -2.0340717|\n",
      "|w3G8B2S7-AUxKCLIw...|gA9hCYY7MYl9oZ3ay...|  4.0|        28253.0|              148.0|  0.4594403|\n",
      "+--------------------+--------------------+-----+---------------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_predictions_on_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:43:53.611988Z",
     "start_time": "2019-10-02T18:43:36.747120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RMSE promedio en el conjunto de prueba es de: 4.407713895692625\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluate_als = RegressionEvaluator(predictionCol='prediction',labelCol='stars', metricName='rmse')\n",
    "get_rmse = evaluate_als.evaluate(get_predictions_on_test)\n",
    "print(f\"El RMSE promedio en el conjunto de prueba es de: {get_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983261906418922"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "users_predictions = get_predictions_on_test\\\n",
    "  .orderBy(col('user_id_indexed'), expr(\"prediction DESC\"))\\\n",
    "  .groupBy('user_id_indexed')\\\n",
    "  .agg(expr('collect_set(business_id_indexed)').alias('user_preds'))\n",
    "\n",
    "get_positive_recs = get_predictions_on_test\\\n",
    "  .where('stars > 2.5')\\\n",
    "  .groupBy('user_id_indexed')\\\n",
    "  .agg(expr('collect_set(business_id_indexed)').alias('likely_preds'))\n",
    "  \n",
    "user_divergence = get_positive_recs.join(users_predictions,['user_id_indexed'])\n",
    "\n",
    "ranking_metrics_on_test = RankingMetrics(user_divergence.rdd.map(lambda x: (x[1], x[2])))\n",
    "ranking_metrics_on_test.meanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para 1 -> 1.0\n",
      "Accuracy para 2 -> 0.552281226626776\n",
      "Accuracy para 3 -> 0.37773123909249573\n",
      "Accuracy para 4 -> 0.28621540762902026\n",
      "Accuracy para 5 -> 0.23006133133881831\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    print(f\"Accuracy para {i} -> {ranking_metrics_on_test.precisionAt(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de Grilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T19:10:47.258590Z",
     "start_time": "2019-10-02T19:10:47.255725Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T19:35:19.172920Z",
     "start_time": "2019-10-02T19:16:47.601973Z"
    }
   },
   "outputs": [],
   "source": [
    "als_instance = ALS(userCol='user_id_indexed',\n",
    "                itemCol='business_id_indexed',\n",
    "                ratingCol='stars',\n",
    "                coldStartStrategy='drop')\n",
    "\n",
    "params = ParamGridBuilder()\\\n",
    "        .addGrid(als_instance.rank,[3, 5, 7, 10])\\\n",
    "        .addGrid(als_instance.regParam, [0.001, 0.1, 1])\\\n",
    "        .build()\n",
    "\n",
    "eval_rmse = RegressionEvaluator(predictionCol='prediction',\n",
    "                               labelCol='stars',\n",
    "                               metricName='rmse')\n",
    "\n",
    "grid_search_als = CrossValidator(estimator=als_instance,\n",
    "                                estimatorParamMaps = params,\n",
    "                                evaluator=eval_rmse,\n",
    "                                numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T19:35:19.172920Z",
     "start_time": "2019-10-02T19:16:47.601973Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_als_train = grid_search_als.fit(yelp_review_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T20:07:23.678925Z",
     "start_time": "2019-10-02T20:07:23.674191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regParam: 3 / rank: 0.001 -> 12.41\n",
      "regParam: 3 / rank: 0.1 -> 4.62\n",
      "regParam: 3 / rank: 1.0 -> 4.22\n",
      "regParam: 5 / rank: 0.001 -> 8.66\n",
      "regParam: 5 / rank: 0.1 -> 4.31\n",
      "regParam: 5 / rank: 1.0 -> 4.04\n",
      "regParam: 7 / rank: 0.001 -> 6.56\n",
      "regParam: 7 / rank: 0.1 -> 4.15\n",
      "regParam: 7 / rank: 1.0 -> 3.97\n",
      "regParam: 10 / rank: 0.001 -> 4.93\n",
      "regParam: 10 / rank: 0.1 -> 4.04\n",
      "regParam: 10 / rank: 1.0 -> 3.94\n"
     ]
    }
   ],
   "source": [
    "for values in zip(params, grid_search_als_train.avgMetrics):\n",
    "    tmp_values = list(values[0].values())\n",
    "    print(f\"regParam: {tmp_values[0]} / rank: {tmp_values[1]} -> {values[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
